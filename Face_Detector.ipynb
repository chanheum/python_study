{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1ETJlUtxTpebCo0phIkvE_n8MIE8mczZ3",
      "authorship_tag": "ABX9TyPa9/yO/YBVptn94QZzzX6Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanheum/python_study/blob/main/Face_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "Z0KlTXEg7Ohm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "#노트북 카메라에서 영상을 읽어온다\n",
        "cap = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "vGFhfy_x7RE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#얼굴 인식 캐스케이드 파일 읽는다\n",
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/opencv-4.x/data/haarcascades/haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "bgMaVAi57YbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if cap.isOpened():\n",
        "    while(True):\n",
        "        # frame 별로 capture 한다\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # 좌우 반전은 1, 상하반전은 0\n",
        "        frame = cv2.flip(frame,1)\n",
        "        # 프레임이 제대로 읽어지지 않은 경우\n",
        "        if not ret:\n",
        "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        #detectMultiScale (InputArray image, std::vector< Rect > &objects, double scaleFactor=1.1, int minNeighbors=3, int flags=0, Size minSize=Size(), Size maxSize=Size())\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.4, 5)\n",
        "\n",
        "        # 빨간 사각형으로 인식된 얼굴을 표시한다.\n",
        "        for (x,y,w,h) in faces:\n",
        "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)\n",
        "\n",
        "        #webCamera라는 이름으로 실시간 화면을 보여준다.\n",
        "        cv2.imshow('webCamera',frame)\n",
        "        # q를 누르면 종료.\n",
        "        if cv2.waitKey(1) == ord('q'):\n",
        "            break\n",
        "else:\n",
        "    print(\"can't open video\")\n",
        "\n",
        "\n",
        "# 메모리를 해제시켜준다.\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "kZ0p716F7Z2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aTasgVP5ZUb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g5dn9gu1N4AV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}